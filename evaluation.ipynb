{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from models import SRResNet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n"
     ]
    }
   ],
   "source": [
    "model_weights = {'srresnet': 'SRResNet.pth',\n",
    "                 #  'srresnet_attention ': 'SRResNet_attention.pth',\n",
    "                 'srgan': 'SRResNet_Discriminator.pth',\n",
    "                 'srgan_efficientnet': \"SRResNet_EfficientNet.pth\",\n",
    "                 'srgan_wgan': 'SRResNet_Discriminator_WGAN.pth'}\n",
    "\n",
    "models = []\n",
    "for key, value in model_weights.items():\n",
    "    model = SRResNet(4, 8 if 'attention' in value else 0, value).to(device)\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_resolve(model, img):\n",
    "    \"\"\"\n",
    "    Apply super-resolution using a given model to a specified image and compare it\n",
    "    with the bicubic-upsampled version. The function processes an image to produce\n",
    "    low-resolution, bicubic-upsampled, and super-resolved versions for evaluation.\n",
    "\n",
    "    :param model: The super-resolution model to be used for image processing.\n",
    "    :param img: Filepath of the high-resolution (HR) image to be processed.\n",
    "    :return: A tuple containing the low-resolution image, the original high-resolution image,\n",
    "             the super-resolved image, and the bicubic-upsampled image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the high-resolution (HR) image from the given file path\n",
    "    hr_img = Image.open(img)\n",
    "    # Ensure the image is in RGB format\n",
    "    hr_img = hr_img.convert('RGB')\n",
    "\n",
    "    # Create a low-resolution (LR) version of the image by downscaling using bicubic interpolation\n",
    "    lr_img = hr_img.resize(\n",
    "        (int(hr_img.width / 4), int(hr_img.height / 4)), Image.BICUBIC)\n",
    "\n",
    "    # Upsample the low-resolution image back to high-resolution using bicubic interpolation\n",
    "    # This serves as a baseline for comparison with the super-resolved image\n",
    "    bicubic_img = lr_img.resize((hr_img.width, hr_img.height), Image.BICUBIC)\n",
    "\n",
    "    # Normalize the low-resolution image for model input according to ImageNet standards\n",
    "    # `convert_image` is assumed to be a function that adjusts image data to model-specific input requirements\n",
    "    imagenet_normed = convert_image(\n",
    "        lr_img, source='pil', target='imagenet-norm')\n",
    "\n",
    "    # Process the normalized low-resolution image using the super-resolution model\n",
    "    # Assuming the model and device (GPU/CPU) are correctly configured\n",
    "    with torch.no_grad():\n",
    "        sr_img = model(imagenet_normed.unsqueeze(0).to(device))\n",
    "\n",
    "    # Remove the batch dimension and move the image data back to CPU, if necessary\n",
    "    sr_img = sr_img.squeeze(0).cpu().detach()\n",
    "\n",
    "    # Convert the model output back to a PIL image from its normalized form\n",
    "    sr_img = convert_image(sr_img, source='[-1, 1]', target='pil')\n",
    "\n",
    "    # Return the processed images\n",
    "    return lr_img, hr_img, sr_img, bicubic_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(sr_imgs, hr_img, bicubic_img, model_names):\n",
    "    # Create grid\n",
    "    margin = 40\n",
    "    num_models = len(model_weights)\n",
    "    # Calculating number of rows to include HR and bicubic at top\n",
    "    rows = (num_models + 2) // 2\n",
    "\n",
    "    # Define the size of the grid image\n",
    "    grid_img = Image.new('RGB',\n",
    "                         (2 * (bicubic_img.width + margin) + margin,\n",
    "                          rows * (hr_img.height + margin) + margin),\n",
    "                         (255, 255, 255))\n",
    "\n",
    "    # Initialize drawing context\n",
    "    draw = ImageDraw.Draw(grid_img)\n",
    "\n",
    "    font = ImageFont.load_default(size=23)\n",
    "\n",
    "    # Place the original HR image in the top left\n",
    "    x_hr = margin\n",
    "    y_hr = margin\n",
    "    grid_img.paste(hr_img, (x_hr, y_hr))\n",
    "    text_size = font.getbbox(\"Original HR\")\n",
    "    draw.text((x_hr + hr_img.width / 2 -\n",
    "               text_size[2] / 2, y_hr - text_size[3] - 10), \"Original HR\", font=font, fill='black')\n",
    "\n",
    "    # Place the bicubic-upsampled image in the top right\n",
    "    x_bicubic = margin + hr_img.width + margin\n",
    "    y_bicubic = margin\n",
    "    grid_img.paste(bicubic_img, (x_bicubic, y_bicubic))\n",
    "    text_size = font.getbbox(\"Bicubic\")\n",
    "    draw.text((x_bicubic + bicubic_img.width / 2 -\n",
    "               text_size[2] / 2, y_bicubic - text_size[3] - 10), \"Bicubic\", font=font, fill='black')\n",
    "\n",
    "    # Loop through SR images and their corresponding model names starting from the second row\n",
    "    row, column = 1, 0  # Start from the second row, first column\n",
    "\n",
    "    for sr_img, model_name in zip(sr_imgs, model_names):\n",
    "        x = margin + column * (sr_img.width + margin)\n",
    "        y = margin + row * (sr_img.height + margin)\n",
    "\n",
    "        # Place image\n",
    "        grid_img.paste(sr_img, (x, y))\n",
    "        text_size = font.getbbox(model_name)\n",
    "        draw.text((x + sr_img.width / 2 -\n",
    "                   text_size[2] / 2, y - text_size[3] - 10), model_name, font=font, fill='black')\n",
    "\n",
    "        # Update column and check if we need to move to the next row\n",
    "        column += 1\n",
    "        if column >= 2:\n",
    "            column = 0\n",
    "            row += 1\n",
    "\n",
    "    # Display the grid image\n",
    "    grid_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01592084/ILSVRC2012_val_00012836.JPEG', '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01582220/ILSVRC2012_val_00003665.JPEG', '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01632777/ILSVRC2012_val_00013940.JPEG']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(50517) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50524) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50532) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50533) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50534) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(50535) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the validation dataset directory\n",
    "test_folder = '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X'\n",
    "\n",
    "# Randomly select 3 folders from the test folder\n",
    "test_images_folders = random.sample(os.listdir(test_folder), 3)\n",
    "\n",
    "# For each selected folder, randomly select one image and construct its full path\n",
    "test_images = [\n",
    "    os.path.join(test_folder, folder, random.sample(os.listdir(\n",
    "        os.path.join(test_folder, folder)), 1)[0])  # Randomly pick one file\n",
    "    for folder in test_images_folders  # Iterate over the selected folders\n",
    "]\n",
    "\n",
    "# Print the paths of the randomly selected images\n",
    "print(test_images)\n",
    "\n",
    "# Loop through each selected test image\n",
    "for test_image in test_images:\n",
    "    # Initialize an empty list to store super-resolved images from each model\n",
    "    sr_imgs = []\n",
    "\n",
    "    # Loop over each model defined in 'models'\n",
    "    for model in models:\n",
    "        # Apply the super-resolution model to the test image\n",
    "        lr_img, hr_img, sr_img, bicubic_img = super_resolve(model, test_image)\n",
    "\n",
    "        # Append the super-resolved image to the list of super-resolved images\n",
    "        sr_imgs.append(sr_img)\n",
    "\n",
    "    # Visualize all super-resolved images along with the high-resolution and bicubic images\n",
    "    visualize_images(sr_imgs, hr_img, bicubic_img, model_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(43989) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(43991) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(43999) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44001) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44002) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44034) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44035) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "test_images = [\n",
    "    \"/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01592084/ILSVRC2012_val_00009374.JPEG\",\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00046767.JPEG',\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00047983.JPEG',\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00048240.JPEG'\n",
    "]\n",
    "for test_image in test_images:\n",
    "    sr_imgs = []\n",
    "    for model in models:\n",
    "        lr_img, hr_img, sr_img, bicubic_img = super_resolve(\n",
    "            model, test_image)\n",
    "        sr_imgs.append(sr_img)\n",
    "    visualize_images(sr_imgs, hr_img, bicubic_img, model_weights.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
