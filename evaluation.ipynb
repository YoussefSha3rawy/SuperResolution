{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from models import SRResNet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n",
      "Model's pretrained weights loaded!\n"
     ]
    }
   ],
   "source": [
    "model_weights = {'srresnet': 'SRResNet.pth',\n",
    "                 #  'srresnet_attention ': 'SRResNet_attention.pth',\n",
    "                 'srgan': 'SRResNet_Discriminator.pth',\n",
    "                 'srgan_efficientnet': \"SRResNet_EfficientNet.pth\",\n",
    "                 'srgan_wgan': 'SRResNet_Discriminator_WGAN.pth'}\n",
    "\n",
    "models = []\n",
    "for key, value in model_weights.items():\n",
    "    model = SRResNet(4, 8 if 'attention' in value else 0, value).to(device)\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def super_resolve(model, img):\n",
    "    \"\"\"\n",
    "    Visualizes the super-resolved images from the SRResNet and SRGAN for comparison with the bicubic-upsampled image\n",
    "    and the original high-resolution (HR) image, as done in the paper.\n",
    "\n",
    "    :param img: filepath of the HR iamge\n",
    "    :param halve: halve each dimension of the HR image to make sure it's not greater than the dimensions of your screen?\n",
    "                  For instance, for a 2160p HR image, the LR image will be of 540p (1080p/4) resolution. On a 1080p screen,\n",
    "                  you will therefore be looking at a comparison between a 540p LR image and a 1080p SR/HR image because\n",
    "                  your 1080p screen can only display the 2160p SR/HR image at a downsampled 1080p. This is only an\n",
    "                  APPARENT rescaling of 2x.\n",
    "                  If you want to reduce HR resolution by a different extent, modify accordingly.\n",
    "    \"\"\"\n",
    "    # Load image, downsample to obtain low-res version\n",
    "    hr_img = Image.open(img, mode=\"r\")\n",
    "    hr_img = hr_img.convert('RGB')\n",
    "    lr_img = hr_img.resize((int(hr_img.width / 4), int(hr_img.height / 4)),\n",
    "                           Image.BICUBIC)\n",
    "\n",
    "    # Bicubic Upsampling\n",
    "    bicubic_img = lr_img.resize((hr_img.width, hr_img.height), Image.BICUBIC)\n",
    "\n",
    "    # Super-resolution (SR) with SRResNet\n",
    "    imagenet_normed = convert_image(\n",
    "        lr_img, source='pil', target='imagenet-norm')\n",
    "\n",
    "    sr_img = model(imagenet_normed.unsqueeze(0).to(device))\n",
    "    sr_img = sr_img.squeeze(0).cpu().detach()\n",
    "    sr_img = convert_image(\n",
    "        sr_img, source='[-1, 1]', target='pil')\n",
    "\n",
    "    return lr_img, hr_img, sr_img, bicubic_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(sr_imgs, hr_img, bicubic_img, model_names):\n",
    "    # Create grid\n",
    "    margin = 40\n",
    "    num_models = len(model_weights)\n",
    "    # Calculating number of rows to include HR and bicubic at top\n",
    "    rows = (num_models + 2) // 2\n",
    "\n",
    "    # Define the size of the grid image\n",
    "    grid_img = Image.new('RGB',\n",
    "                         (2 * (bicubic_img.width + margin) + margin,\n",
    "                          rows * (hr_img.height + margin) + margin),\n",
    "                         (255, 255, 255))\n",
    "\n",
    "    # Initialize drawing context\n",
    "    draw = ImageDraw.Draw(grid_img)\n",
    "\n",
    "    font = ImageFont.load_default(size=23)\n",
    "\n",
    "    # Place the original HR image in the top left\n",
    "    x_hr = margin\n",
    "    y_hr = margin\n",
    "    grid_img.paste(hr_img, (x_hr, y_hr))\n",
    "    text_size = font.getbbox(\"Original HR\")\n",
    "    draw.text((x_hr + hr_img.width / 2 -\n",
    "               text_size[2] / 2, y_hr - text_size[3] - 10), \"Original HR\", font=font, fill='black')\n",
    "\n",
    "    # Place the bicubic-upsampled image in the top right\n",
    "    x_bicubic = margin + hr_img.width + margin\n",
    "    y_bicubic = margin\n",
    "    grid_img.paste(bicubic_img, (x_bicubic, y_bicubic))\n",
    "    text_size = font.getbbox(\"Bicubic\")\n",
    "    draw.text((x_bicubic + bicubic_img.width / 2 -\n",
    "               text_size[2] / 2, y_bicubic - text_size[3] - 10), \"Bicubic\", font=font, fill='black')\n",
    "\n",
    "    # Loop through SR images and their corresponding model names starting from the second row\n",
    "    row, column = 1, 0  # Start from the second row, first column\n",
    "\n",
    "    for sr_img, model_name in zip(sr_imgs, model_names):\n",
    "        x = margin + column * (sr_img.width + margin)\n",
    "        y = margin + row * (sr_img.height + margin)\n",
    "\n",
    "        # Place image\n",
    "        grid_img.paste(sr_img, (x, y))\n",
    "        text_size = font.getbbox(model_name)\n",
    "        draw.text((x + sr_img.width / 2 -\n",
    "                   text_size[2] / 2, y - text_size[3] - 10), model_name, font=font, fill='black')\n",
    "\n",
    "        # Update column and check if we need to move to the next row\n",
    "        column += 1\n",
    "        if column >= 2:\n",
    "            column = 0\n",
    "            row += 1\n",
    "\n",
    "    # Display the grid image\n",
    "    grid_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(43989) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(43991) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(43999) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44000) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44001) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44002) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44034) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(44035) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "test_images = [\n",
    "    \"/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01592084/ILSVRC2012_val_00009374.JPEG\",\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00046767.JPEG',\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00047983.JPEG',\n",
    "    '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n02077923/ILSVRC2012_val_00048240.JPEG'\n",
    "]\n",
    "for test_image in test_images:\n",
    "    sr_imgs = []\n",
    "    for model in models:\n",
    "        lr_img, hr_img, sr_img, bicubic_img = super_resolve(\n",
    "            model, test_image)\n",
    "        sr_imgs.append(sr_img)\n",
    "    visualize_images(sr_imgs, hr_img, bicubic_img, model_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01986214/ILSVRC2012_val_00021819.JPEG', '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01924916/ILSVRC2012_val_00049105.JPEG', '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X/n01695060/ILSVRC2012_val_00008095.JPEG']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(41585) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(41618) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(41626) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(41627) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(41630) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(41631) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "test_folder = '/Users/youssefshaarawy/Documents/Datasets/INM705/data/val.X'\n",
    "test_images_folders = random.sample(os.listdir(test_folder), 3)\n",
    "test_images = [os.path.join(test_folder, folder, random.sample(os.listdir(\n",
    "    os.path.join(test_folder, folder)), 1)[0]) for folder in test_images_folders]\n",
    "print(test_images)\n",
    "for test_image in test_images:\n",
    "    sr_imgs = []\n",
    "    for model in models:\n",
    "        lr_img, hr_img, sr_img, bicubic_img = super_resolve(\n",
    "            model, test_image)\n",
    "        sr_imgs.append(sr_img)\n",
    "    visualize_images(sr_imgs, hr_img, bicubic_img, model_weights.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
