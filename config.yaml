generator:
  # kernel size of the first and last convolutions which transform the inputs and outputs
  # large_kernel_size: 9
  # # kernel size of all convolutions in-between, i.e. those in the residual and subpixel convolutional blocks
  # small_kernel_size: 3
  # n_channels: 64  # number of channels in-between, i.e. the input and output channels for the residual and subpixel convolutional blocks
  # n_blocks: 16  # number of residual blocks
  # num_heads: 8 # number of heads for multihead attention.
  checkpoint: SRResNet.pth
discriminator:
  kernel_size: 3  # kernel size in all convolutional blocks
  n_channels: 64  # number of output channels in the first convolutional block, after which it is doubled in every 2nd block thereafter
  n_blocks: 8  # number of convolutional blocks
  fc_size: 1024  # size of the first fully connected layer
train:
  # Learning parameters
  # checkpoint: None  # path to model checkpoint, None if none
  epochs: 100  # number of training epochs
  lr: 1e-4  # learning rate
  # grad_clip: None  # clip if gradients are exploding
  early_stopping: 20
dataset:
  # Data parameters
  data_folder: ./data  # folder with JSON data files
  crop_size: 96  # crop size of target HR images
  scaling_factor: 4  # the scaling factor for the generator; the input LR images will be downsampled from the target HR images by this factor
train_dataloader:
  batch_size: 32
  shuffle: True
  num_workers: 4
test_dataloader:
  batch_size: 1
  shuffle: False
  num_workers: 4